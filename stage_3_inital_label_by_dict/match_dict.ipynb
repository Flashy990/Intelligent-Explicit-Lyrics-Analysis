{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DuXJP1lfzvS7",
    "outputId": "31107c4c-e277-4d51-e671-93c1d2bb0b76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define special words that should not be changed\n",
    "special_words = {\"ass\"}  # Add any other specific words here\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'[,\\.\\!?:()\"]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    # Apply only lemmatization, but keep special words unchanged\n",
    "    words = [word if word in special_words else lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def normalize_word(word):\n",
    "    # Keep special words unchanged, apply lemmatization otherwise\n",
    "    return word if word in special_words else lemmatizer.lemmatize(word)\n",
    "\n",
    "def preprocess_word_dict(word_dict_df):\n",
    "    normalized_dict = {}\n",
    "    for category in word_dict_df.columns:\n",
    "        normalized_dict[category] = []\n",
    "        for phrase in word_dict_df[category].dropna():\n",
    "            words = phrase.split()  # Split phrases into individual words\n",
    "            # Normalize each word in the phrase\n",
    "            normalized_phrase = ' '.join([normalize_word(word) for word in words])\n",
    "            normalized_dict[category].append(normalized_phrase)  # Store the normalized phrase\n",
    "    return normalized_dict\n",
    "\n",
    "def label_lyrics_by_category(lyrics_df, normalized_dict):\n",
    "    for category, keywords in normalized_dict.items():\n",
    "        lyrics_df['normalized_lyrics'] = lyrics_df['lyrics'].apply(\n",
    "            lambda text: ' '.join([normalize_word(word) for word in text.split()])\n",
    "        )\n",
    "\n",
    "        # Use regex to match whole words or phrases accurately\n",
    "        lyrics_df[category] = lyrics_df['normalized_lyrics'].apply(\n",
    "            lambda text: 'T' if any(re.search(rf'\\b{re.escape(phrase)}\\b', text) for phrase in keywords) else 'F'\n",
    "        )\n",
    "        lyrics_df[f\"{category}_words\"] = lyrics_df['normalized_lyrics'].apply(\n",
    "            lambda text: ', '.join(phrase for phrase in keywords if re.search(rf'\\b{re.escape(phrase)}\\b', text))\n",
    "        )\n",
    "\n",
    "    # Define Explicit_by_def column: T if any category is T, else F\n",
    "    lyrics_df['Explicit_by_def'] = lyrics_df[['Sexual', 'Violence', 'Substance', 'Language']].apply(\n",
    "        lambda row: 'T' if 'T' in row.values else 'F', axis=1\n",
    "    )\n",
    "\n",
    "    return lyrics_df\n",
    "\n",
    "def save_combined_results(lyrics_df, output_path):\n",
    "    lyrics_df.drop(columns=['normalized_lyrics'], inplace=True)\n",
    "    lyrics_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    print(\"File has been generated successfully!\")\n",
    "\n",
    "# Load data files\n",
    "word_dict_df = pd.read_csv('expanded_word_dict_2.csv')\n",
    "lyrics_df = pd.read_csv('clean_unlabeled_utf8.csv')\n",
    "\n",
    "# Preprocess word dictionary and lyrics\n",
    "normalized_dict = preprocess_word_dict(word_dict_df)\n",
    "lyrics_df['lyrics'] = lyrics_df['lyrics'].apply(preprocess_text)\n",
    "\n",
    "# Label lyrics based on category keywords\n",
    "lyrics_df = label_lyrics_by_category(lyrics_df, normalized_dict)\n",
    "\n",
    "# Save the results to a single CSV file\n",
    "output_path = 'labeled_by_dict.csv'\n",
    "save_combined_results(lyrics_df, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
